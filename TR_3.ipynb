{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreahorbach/SeminarMSV/blob/main/TR_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfJsWPpAK-3f"
      },
      "source": [
        "## Sitzung 3: Authorship Attribution und Machine Learning\n",
        "Der Code zur heutigen Sitzung folgt teilweise Kapitel 5 und 6 aus \"Getting Started with Natural Language Processing\" von Ekaterina Kochmar."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schritt 1: Daten**\n",
        "Wie letzte Woche benutzen wir das nltk Gutenberg Corpus. Wir wollen einen Klassifikator bauen, der lernt Texte von William Shakespeare von Texten von Jane Austen zu unterscheiden. Wir laden also wieder die entsprechenden Corpora."
      ],
      "metadata": {
        "id": "AjBMmXxTQcs7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHlLrabSJNPJ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "gutenberg.fileids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gp4066itqa5w"
      },
      "outputs": [],
      "source": [
        "austen1 = gutenberg.sents('austen-emma.txt')\n",
        "austen2 = gutenberg.sents('austen-persuasion.txt')\n",
        "austen3 = gutenberg.sents('austen-sense.txt')\n",
        "shakespeare1 = gutenberg.sents(\"shakespeare-caesar.txt\")\n",
        "shakespeare2 = gutenberg.sents(\"shakespeare-hamlet.txt\")\n",
        "shakespeare3 = gutenberg.sents(\"shakespeare-macbeth.txt\")\n",
        "print (austen1, len(austen1))\n",
        "print (austen2, len(austen2))\n",
        "print (austen3, len(austen3))\n",
        "print (shakespeare1, len(shakespeare1))\n",
        "print (shakespeare2, len(shakespeare2))\n",
        "print (shakespeare3, len(shakespeare3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schritt 2: Bücher in kleinere Abschnitte zerlegen**\n",
        "beim klassischen Machine Learning brauchen wir möglichst viele Trainingsdaten. Daher zerlegen wir jedes Buch in Sätze. Zusätzlich bekommt jeder Satz ein Label, den Autorennamen.\n",
        "Wir wollen verhindern, dass unser Klassifikator ein Topic lernt (Wenn der Text 'Hamlet' enthält, ist es von Shakespeare.) Deswegen kombinieren wir Trainingsdaten aus jeweils zwei Büchern pro Autor und testen auf dem dritten Buch."
      ],
      "metadata": {
        "id": "R7AREm3dQ0v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = [(sent, \"austen\") for sent in austen1]\n",
        "train_set += [(sent, \"austen\") for sent in austen2]\n",
        "train_set += [(sent, \"shakespeare\") for sent in shakespeare1]\n",
        "train_set += [(sent, \"shakespeare\") for sent in shakespeare2]\n",
        "test_set = [(sent, \"austen\") for sent in austen3]\n",
        "test_set += [(sent, \"shakespeare\") for sent in shakespeare3]\n",
        "print (f\"Training dataset size = {str(len(train_set))} sentences\")\n",
        "print (f\"Test dataset size = {str(len(test_set))} sentences\")"
      ],
      "metadata": {
        "id": "jNSLPdDvS-Qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schritt 3: Ein erster Classifier**\n",
        "Wie letzte Woche verwenden wir Längenmerkmale. Wie viele Wörter hat ein Satz? Wie viele Buchstaben hat ein Wort? Diese Merkmale extrahieren wir für jeden einzelnen Textabschnitt."
      ],
      "metadata": {
        "id": "8ADsc2ZDRKya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#average word length in characters\n",
        "def avg_number_chars(text):\n",
        "    total_chars = 0.0\n",
        "    for word in text:\n",
        "        total_chars += len(word)\n",
        "    return float(total_chars)/float(len(text))\n",
        "\n",
        "#number of wors in a text\n",
        "def number_words(text):\n",
        "    return float(len(text)) # len() gibt die Länge einer Liste an, in unserem Fall ist ein Satz eine Liste von WÖrtern\n",
        "\n",
        "print(avg_number_chars([\"Not\", \"so\", \"happy\", \",\", \"yet\", \"much\", \"happyer\"]))\n",
        "print(number_words([\"Not\", \"so\", \"happy\", \",\", \"yet\", \"much\", \"happyer\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuWio-a_ZUIA",
        "outputId": "e50aa29d-adc8-4be9-ce88-49055f95d11f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5714285714285716\n",
            "7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aufgabe 1**\n",
        "Erweitern Sie den Feature-Extractions-Code oben, so dass er zusätzlich auch noch das Verhältnis von unterschiedlichen Wörtern zur Gesamtzahl der Wörter (Type-Token-Ratio) berücksichtigt. Tipp: Bedienen Sie sich im Code von letzter Woche."
      ],
      "metadata": {
        "id": "X9PXg527Ruu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_dataset(source):\n",
        "    all_features = [] # Merkmale\n",
        "    targets = [] # Gold labels\n",
        "    for (sent, label) in source:\n",
        "        feature_list=[]\n",
        "        feature_list.append(avg_number_chars(sent))\n",
        "        feature_list.append(number_words(sent))\n",
        "        all_features.append(feature_list)\n",
        "        if label==\"austen\": targets.append(0)\n",
        "        else: targets.append(1)\n",
        "    return all_features, targets\n",
        "\n",
        "train_data, train_targets = initialize_dataset(train_set)\n",
        "test_data, test_targets = initialize_dataset(test_set)\n",
        "\n",
        "print (len(train_data), len(train_targets))\n",
        "print (len(test_data), len(test_targets))"
      ],
      "metadata": {
        "id": "7xSy6hoKamaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "text_clf = DecisionTreeClassifier(random_state=42)\n",
        "text_clf.fit(train_data, train_targets)\n",
        "\n",
        "def evaluate(predicted, targets):\n",
        "    print(np.mean(predicted == targets)) # wie häufig ist das predictete Label das gleiche wie das gold label? Das ist die Accuracy.\n",
        "    print(metrics.confusion_matrix(targets, predicted))\n",
        "    print(metrics.classification_report(targets, predicted))\n",
        "\n",
        "# we test and evaluate on the test data\n",
        "predicted = text_clf.predict(test_data)\n",
        "evaluate(predicted, test_targets)\n",
        "\n",
        "# for comparison, we also apply and evaluate on the training data\n",
        "predicted = text_clf.predict(train_data)\n",
        "evaluate(predicted, train_targets)\n",
        "\n"
      ],
      "metadata": {
        "id": "w_o_fjV3aUKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aufgabe 2** Vergleichen Sie die Performanz auf den Trainingsdaten und den Testdaten. War das Ergebnis so erwartbar?"
      ],
      "metadata": {
        "id": "ZgRDh6io6RGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schritt 4:** Wir nutzen auch Häufigkeiten der einzelnen Wortarten als Features. (Sie sehen, dass wir viel Code von letzter Woche wiederverwenden.)"
      ],
      "metadata": {
        "id": "SmbdXYZu5iAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def map_fine_to_coarse(pos_tag):\n",
        "    if pos_tag.startswith('N'):\n",
        "        return 'Noun'\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return 'Verb'\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return 'Adverb'\n",
        "    elif pos_tag.startswith('J'):\n",
        "        return 'Adjective'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "def pos_frequency(text):\n",
        "    features = []\n",
        "    pos_tags = pos_tag(text)\n",
        "    tags = ['Noun', 'Verb', 'Adverb', 'Adjective', 'Other']\n",
        "\n",
        "    #Weise jedem Wort seine Wortart zu\n",
        "    pos_tag_frequency = Counter(map_fine_to_coarse(tag) for word, tag in pos_tags)\n",
        "    # Calculate total number of POS tags\n",
        "    total_pos_tags = sum(pos_tag_frequency.values())\n",
        "\n",
        "    # add the relative frequencies as features\n",
        "    for tag in tags:\n",
        "      features.append(float(pos_tag_frequency[tag] / total_pos_tags))\n",
        "    return features\n",
        "\n",
        "print(pos_frequency([\"This\", \"is\", \"an\", \"example\", \"text\", \".\"]))"
      ],
      "metadata": {
        "id": "9zwYffSr7ShP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schritt 5** Wir berechnen unseren Datensatz neu. Das kann etwas dauern, weil POS-Tagging Zeit kostet."
      ],
      "metadata": {
        "id": "jOq3FfohB6tW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_dataset(source):\n",
        "    all_features = []\n",
        "    targets = []\n",
        "    for (sent, label) in source:\n",
        "        feature_list=[]\n",
        "        feature_list.append(avg_number_chars(sent))\n",
        "        feature_list.append(number_words(sent))\n",
        "        feature_list = feature_list + pos_frequency(sent) # hier ist die entscheidende neue Zeile gegenüber Schritt 3. Alles andere ist gleich.\n",
        "        all_features.append(feature_list)\n",
        "        if label==\"austen\": targets.append(0)\n",
        "        else: targets.append(1)\n",
        "    return all_features, targets\n",
        "\n",
        "train_data, train_targets = initialize_dataset(train_set)\n",
        "test_data, test_targets = initialize_dataset(test_set)\n",
        "\n",
        "print (len(train_data), len(train_targets))\n",
        "print (len(test_data), len(test_targets))"
      ],
      "metadata": {
        "id": "giqzVkdb_Eq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schritt 6** Wir lassen den Klassifikator nochmal neu laufen und vergleichen die Ergebnisse."
      ],
      "metadata": {
        "id": "a6D_lEvfCGP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf = DecisionTreeClassifier(random_state=42)\n",
        "text_clf.fit(train_data, train_targets)\n",
        "\n",
        "# we test and evaluate on the test data\n",
        "predicted = text_clf.predict(test_data)\n",
        "evaluate(predicted, test_targets)\n",
        "\n",
        "# for comparison, we also apply and evaluate on the training data\n",
        "predicted = text_clf.predict(train_data)\n",
        "evaluate(predicted, train_targets)"
      ],
      "metadata": {
        "id": "G3_BR2qHCN54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aufgabe 3** Vergleichen Sie die Werte. Wurde der ALgorithmus besser?"
      ],
      "metadata": {
        "id": "5RRf0QT7CZ3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aufgabe 4** Bauen Sie auch die Häufigkeit der häufigsten 20 Wörter als Feature ein. Gehen Sie dazu in 2 Schritten vor:\n",
        "a) Bestimmen Sie die häufigsten Wörter auf den Trainingsdaten.\n",
        "b) Bestimmen Sie für jedes dieser Features die relative Häufigkeit für jeden Satz und integrieren Sie das in Ihre Datensatzinitialisierung."
      ],
      "metadata": {
        "id": "dc0FmBsECiMl"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0b7nOenDQ69nA2qbCHgfW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}