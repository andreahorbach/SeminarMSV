{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmKhg8TFWBce89TahYLNvN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreahorbach/SeminarMSV/blob/main/TR_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sitzung 2: Authorship Attribution\n",
        "Der Code zur heutigen Sitzung folgt lose Kapitel 5 aus \"Getting Started with Natural Language Processing\" von Ekaterina Kochmar."
      ],
      "metadata": {
        "id": "YfJsWPpAK-3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schritt 1:** Wir laden das Gutenberg-Corpus und lassen uns die darin enthaltenen Titel anzeigen. Von Jane Austen und William Shakespeare gibt es je drei Bücher. Sie werden wir im Folgenden für unsere Beispiele verwenden."
      ],
      "metadata": {
        "id": "G1dTrFMDGbqq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHlLrabSJNPJ"
      },
      "outputs": [],
      "source": [
        "import nltk # nltk = Natural Language Toolkit, eine große open-source-NLP-Bibliothek\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "gutenberg.fileids() # Zeige alle Dateien im Gutenberg-Corpus an"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "austen1 = gutenberg.sents('austen-emma.txt') # Wir lassen uns eine Liste der Sätze zurückgeben.\n",
        "austen2 = gutenberg.sents('austen-persuasion.txt')\n",
        "austen3 = gutenberg.sents('austen-sense.txt')\n",
        "shakespeare1 = gutenberg.sents(\"shakespeare-caesar.txt\")\n",
        "shakespeare2 = gutenberg.sents(\"shakespeare-hamlet.txt\")\n",
        "shakespeare3 = gutenberg.sents(\"shakespeare-macbeth.txt\")\n",
        "print (austen1, len(austen1)) # Wir schreiben den Namen der Datei und die Anzahl der Sätze raus.\n",
        "print (austen2, len(austen2))\n",
        "print (austen3, len(austen3))\n",
        "print (shakespeare1, len(shakespeare1))\n",
        "print (shakespeare2, len(shakespeare2))\n",
        "print (shakespeare3, len(shakespeare3))"
      ],
      "metadata": {
        "id": "Gp4066itqa5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schritt 2** Als nächstes geben wir eine erste Statistik zu den 6 Büchern von Austen und Shakespeare aus: Wieviele Wörter hat ein durschnittlicher Satz? Wieviele Buchstaben ein Wort? Und wie oft kommt ein Wort im Schnitt vor?"
      ],
      "metadata": {
        "id": "qZdlNO4THdE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def statistics(gutenberg_data):\n",
        "    print(f\"{'words_length': <20} {'sentence_length': <20} {'Avg Word Frequency': <20} {'Book': <20}\")\n",
        "    print(\"-\" * 80)\n",
        "    for work in gutenberg_data:\n",
        "        num_chars = len(gutenberg.raw(work)) # Anzahl Buchstaben\n",
        "        num_words = len(gutenberg.words(work)) # Anzahl Wörter\n",
        "        num_sents = len(gutenberg.sents(work)) # Anzahl Sätze\n",
        "        num_vocab = len(set(w.lower() for w in gutenberg.words(work))) # Anzahl verschiedener Wörter = Vokabulargröße\n",
        "        print(f\"{round(num_chars/num_words): <20}\",  # average word length in characters\n",
        "             f\"{round(num_words/num_sents): <20}\", # average sentence length in words\n",
        "             f\"{round(num_words/num_vocab): <20}\", # average number of times each word occurs\n",
        "             f\"{work: <20}\")\n",
        "\n",
        "gutenberg_data = ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt',\n",
        "                 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt']\n",
        "statistics(gutenberg_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOay8pq1q-hB",
        "outputId": "3aa04a11-ee3b-419f-e2ef-6434de7d1cba"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words_length         sentence_length      Avg Word Frequency   Book                \n",
            "--------------------------------------------------------------------------------\n",
            "5                    25                   26                   austen-emma.txt     \n",
            "5                    26                   17                   austen-persuasion.txt\n",
            "5                    28                   22                   austen-sense.txt    \n",
            "4                    12                   9                    shakespeare-caesar.txt\n",
            "4                    12                   8                    shakespeare-hamlet.txt\n",
            "4                    12                   7                    shakespeare-macbeth.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aufgabe** Überlegen Sie, bei welchem der drei Maße die Länge des Textes eine Rolle spielt."
      ],
      "metadata": {
        "id": "JVS4JF-AH2xE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aufgabe** Ergänzen Sie den Code so, dass auch die drei Bücher von G. K. Chesterton analysiert werden."
      ],
      "metadata": {
        "id": "kfUoluEQIjjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schritt 3** Wir schauen uns die Verteilung der verschiedenen Wortarten an."
      ],
      "metadata": {
        "id": "P9n9ra-EIDnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def map_fine_to_coarse(pos_tag):\n",
        "    if pos_tag.startswith('N'):\n",
        "        return 'Noun'\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return 'Verb'\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return 'Adverb'\n",
        "    elif pos_tag.startswith('J'):\n",
        "        return 'Adjective'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "def process(gutenberg_data):\n",
        "   for work in gutenberg_data:\n",
        "      print(\"\\n\", work)\n",
        "      text = gutenberg.raw(work)\n",
        "      text = text[0:100000]\n",
        "      words = word_tokenize(text)\n",
        "      pos_tags = pos_tag(words)\n",
        "\n",
        "      #Weise jedem Wort seine Wortart zu\n",
        "      print(pos_tags)\n",
        "      pos_tag_frequency = Counter(map_fine_to_coarse(tag) for word, tag in pos_tags)\n",
        "      # Calculate total number of POS tags\n",
        "      total_pos_tags = sum(pos_tag_frequency.values())\n",
        "\n",
        "      # Print the relative frequencies\n",
        "      for tag, count in pos_tag_frequency.items():\n",
        "        relative_frequency = count / total_pos_tags\n",
        "        print(f\"{tag}: {relative_frequency:.4f}\")\n",
        "\n",
        "gutenberg_data = ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt',\n",
        "                 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt']\n",
        "process(gutenberg_data)"
      ],
      "metadata": {
        "id": "_U_pLx64yR_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aufgabe** Modifizieren Sie den Code, so, dass Sie auch die Häufigkeit von Artikeln und Präpositionen angezeigt bekommen. Eine Übersicht der verschiedenen POS Tags finden Sie hier: https://www.sketchengine.eu/penn-treebank-tagset/"
      ],
      "metadata": {
        "id": "hh1EhQTDIM9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schritt 4** Wir geben eine Statistik über die häufigsten Wörter aus."
      ],
      "metadata": {
        "id": "0ZP6m_OaJM8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_words_statistics(gutenberg_data):\n",
        "  for work in gutenberg_data:\n",
        "      print(\"\\n\", work)\n",
        "      text = gutenberg.raw(work)[0:100000]\n",
        "      # Tokenize the text into words\n",
        "      words = word_tokenize(text)\n",
        "\n",
        "      # Count the frequency of each word\n",
        "      word_frequency = Counter(words)\n",
        "\n",
        "      # Get the 10 most frequent words\n",
        "      top_words = word_frequency.most_common(20)\n",
        "\n",
        "      # Calculate total number of words\n",
        "      total_words = len(words)\n",
        "\n",
        "      # Print statistics for the top 20 words\n",
        "      print(f\"{'Word': <15}{'Frequency': <15}{'Relative Frequency': <20}\")\n",
        "      print(\"-\" * 50)\n",
        "      for word, count in top_words:\n",
        "          relative_frequency = count / total_words\n",
        "          print(f\"{word: <15}{count: <15}{relative_frequency:.4f}\")\n",
        "\n",
        "\n",
        "get_top_words_statistics(gutenberg_data)"
      ],
      "metadata": {
        "id": "IB65Q0xr8ubB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}